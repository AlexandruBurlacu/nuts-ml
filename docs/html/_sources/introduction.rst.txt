Introduction
============

Typical deep-learning code shows certain characteristics such as

- data pre-processing on CPU and training on GPU
- mix of common and task-specific pre-processing steps
- training data does not fit in memory and is processed in mini-batches
- data augmentation to increase amount of training data
- check-pointing of network weights during training
- logging of training progress

These functions can be implemented as generalized components and arranged
in a pipeline structure.


Canonical pipeline
------------------

The *canonical pipeline* for deep-learning, specifically for image data,
is depicted below

.. image:: pics/pipeline.png

Data is processed in small batches or single images by a sequence of 
components

- *Reader*: sample data stored in CSV files, `Pandas <http://pandas.pydata.org/>`_ 
  tables, databases or other data sources is read,

- *Splitter*: samples are split into training, validation and sets, and stratified
  if necessary,

- *Loader*: image data is loaded for each sample when needed,

- *Transformer*: images are transformed, e.g. cropped or resized,

- *Augmenter*: images are augmented to increase data size by random rotations,
   flipping, changes to contrast, or others,

- *Batcher*: the transformed and augmented images are organized in mini-batches 
   for GPU processing,

- *Network*: a neural network is trained and evaluated on the GPU,

- *Logger*: the network performance (loss, accuracy, ...) is logged or plotted.

Depending on the actual task (training, testing, evaluation, ...) or data type
(image, video, text) some of the processing steps will differ but many components 
can be shared between applications. 


Library
-------

**nuts-ml** is a library that provides common data-processing and machine learning 
components as so called ‘nuts’. 
**nuts-ml** is based on `nuts-flow <https://maet3608.github.io/nuts-flow/>`_,
which itself is based on Python iterators and 
`itertools <https://docs.python.org/2/library/itertools.html>`_

.. image:: pics/architecture.png
   :align: center

**nuts-flow** wraps iterators and itertool functions into *nuts* that provide a 
``>>`` operator to enable compositions of iterators as pipelines. For instance,
a nested itertool expression such as the following

.. code:: Python

  list(islice(ifilter(lambda x: x > 5, xrange(10)), 3))

can be *flattened* and more clearly written with **nuts-flow** as

.. code:: Python

  Range(10) >> Filter(_ > 5) >> Take(3) >> Collect()

**nuts-ml** adds nuts specifically for machine learning and (image) data 
processing. The following example gives a taste of a **nuts-ml** pipeline:

.. code:: python

  train_samples >> PrintProgress(train_samples) >>
    load_image >> transform >> augment >> Shuffle(100) >>
    build_batch >> network.train() >> Consume()

Nuts can be freely arranged to build data flows that are efficient, 
easy to understand and easy to modify.